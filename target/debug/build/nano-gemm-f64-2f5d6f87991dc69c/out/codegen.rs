
        #[cfg(any(target_arch = "x86", target_arch = "x86_64"))]
        pub mod x86 {
            #[cfg(target_arch = "x86_64")]
            use core::arch::x86_64::*;
            #[cfg(target_arch = "x86")]
            use core::arch::x86::*;

        #[inline(always)]
        unsafe fn splat_1d(x: f64) -> __m128d {
            _mm_load_sd(&x)
        }
        pub mod f64 {
pub mod f64x1 {
pub const MR_DIV_N: usize = 1; pub const NR: usize = 4; pub const N: usize = 1;
            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 15;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
}if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 15;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
}if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 15;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
}if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_sd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 15;
tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 1;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_load_sd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = crate::x86::splat_1d(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_sd(tmp_lhs[0], tmp_rhs, acc[0][3]);
}if alpha == 1.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_load_sd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_load_sd(dst)));
}}else if alpha == 0.0 {let beta = crate::x86::splat_1d(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_mul_sd(beta, acc[0][3]));
}}else {let beta = crate::x86::splat_1d(beta);
let alpha = crate::x86::splat_1d(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][0], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][1], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][2], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_store_sd(dst, _mm_fmadd_sd(beta, acc[0][3], _mm_mul_sd(_mm_load_sd(dst), alpha)));
}}}
pub static MICROKERNELS: [[[nano_gemm_core::MicroKernel<f64>; 4]; 1]; 17] = [
[
[
matmul_1_1_1,matmul_1_2_1,matmul_1_3_1,matmul_1_4_1,],
],
[
[
matmul_1_1_2,matmul_1_2_2,matmul_1_3_2,matmul_1_4_2,],
],
[
[
matmul_1_1_3,matmul_1_2_3,matmul_1_3_3,matmul_1_4_3,],
],
[
[
matmul_1_1_4,matmul_1_2_4,matmul_1_3_4,matmul_1_4_4,],
],
[
[
matmul_1_1_5,matmul_1_2_5,matmul_1_3_5,matmul_1_4_5,],
],
[
[
matmul_1_1_6,matmul_1_2_6,matmul_1_3_6,matmul_1_4_6,],
],
[
[
matmul_1_1_7,matmul_1_2_7,matmul_1_3_7,matmul_1_4_7,],
],
[
[
matmul_1_1_8,matmul_1_2_8,matmul_1_3_8,matmul_1_4_8,],
],
[
[
matmul_1_1_9,matmul_1_2_9,matmul_1_3_9,matmul_1_4_9,],
],
[
[
matmul_1_1_10,matmul_1_2_10,matmul_1_3_10,matmul_1_4_10,],
],
[
[
matmul_1_1_11,matmul_1_2_11,matmul_1_3_11,matmul_1_4_11,],
],
[
[
matmul_1_1_12,matmul_1_2_12,matmul_1_3_12,matmul_1_4_12,],
],
[
[
matmul_1_1_13,matmul_1_2_13,matmul_1_3_13,matmul_1_4_13,],
],
[
[
matmul_1_1_14,matmul_1_2_14,matmul_1_3_14,matmul_1_4_14,],
],
[
[
matmul_1_1_15,matmul_1_2_15,matmul_1_3_15,matmul_1_4_15,],
],
[
[
matmul_1_1_16,matmul_1_2_16,matmul_1_3_16,matmul_1_4_16,],
],
[
[
matmul_1_1_dyn,matmul_1_2_dyn,matmul_1_3_dyn,matmul_1_4_dyn,],
],
];
}
pub mod f64x2 {
pub const MR_DIV_N: usize = 1; pub const NR: usize = 4; pub const N: usize = 2;
            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 15;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
}if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 15;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
}if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 15;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
}if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
let depth = 0;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 15;
tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m128d;
const N: isize = 2;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
_ = last_mask;
for depth in 0..k as isize {tmp_lhs[0] = _mm_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
}if alpha == 1.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_loadu_pd(dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_loadu_pd(dst)));
}}else if alpha == 0.0 {let beta = _mm_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm_set1_pd(beta);
let alpha = _mm_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][0], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][1], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][2], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm_storeu_pd(dst, _mm_fmadd_pd(beta, acc[0][3], _mm_mul_pd(_mm_loadu_pd(dst), alpha)));
}}}
pub static MICROKERNELS: [[[nano_gemm_core::MicroKernel<f64>; 4]; 1]; 17] = [
[
[
matmul_1_1_1,matmul_1_2_1,matmul_1_3_1,matmul_1_4_1,],
],
[
[
matmul_1_1_2,matmul_1_2_2,matmul_1_3_2,matmul_1_4_2,],
],
[
[
matmul_1_1_3,matmul_1_2_3,matmul_1_3_3,matmul_1_4_3,],
],
[
[
matmul_1_1_4,matmul_1_2_4,matmul_1_3_4,matmul_1_4_4,],
],
[
[
matmul_1_1_5,matmul_1_2_5,matmul_1_3_5,matmul_1_4_5,],
],
[
[
matmul_1_1_6,matmul_1_2_6,matmul_1_3_6,matmul_1_4_6,],
],
[
[
matmul_1_1_7,matmul_1_2_7,matmul_1_3_7,matmul_1_4_7,],
],
[
[
matmul_1_1_8,matmul_1_2_8,matmul_1_3_8,matmul_1_4_8,],
],
[
[
matmul_1_1_9,matmul_1_2_9,matmul_1_3_9,matmul_1_4_9,],
],
[
[
matmul_1_1_10,matmul_1_2_10,matmul_1_3_10,matmul_1_4_10,],
],
[
[
matmul_1_1_11,matmul_1_2_11,matmul_1_3_11,matmul_1_4_11,],
],
[
[
matmul_1_1_12,matmul_1_2_12,matmul_1_3_12,matmul_1_4_12,],
],
[
[
matmul_1_1_13,matmul_1_2_13,matmul_1_3_13,matmul_1_4_13,],
],
[
[
matmul_1_1_14,matmul_1_2_14,matmul_1_3_14,matmul_1_4_14,],
],
[
[
matmul_1_1_15,matmul_1_2_15,matmul_1_3_15,matmul_1_4_15,],
],
[
[
matmul_1_1_16,matmul_1_2_16,matmul_1_3_16,matmul_1_4_16,],
],
[
[
matmul_1_1_dyn,matmul_1_2_dyn,matmul_1_3_dyn,matmul_1_4_dyn,],
],
];
}

        pub mod avx {
pub const MR_DIV_N: usize = 2; pub const NR: usize = 4; pub const N: usize = 4;
            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 15;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 15;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 15;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 15;
tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_1_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 0 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 15;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 15;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 15;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
let depth = 0;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm256_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 13;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 14;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 15;
tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}

            #[target_feature(enable = "avx,avx2,fma")]
pub unsafe fn matmul_2_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m256d;
const N: isize = 4;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const __m256i);
for depth in 0..k as isize {tmp_lhs[0] = _mm256_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm256_maskload_pd(lhs.offset(depth * lhs_cs + 1 * N), last_mask);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm256_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm256_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm256_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
}if alpha == 1.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_maskload_pd(dst, last_mask)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_maskload_pd(dst, last_mask)));
}}else if alpha == 0.0 {let beta = _mm256_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm256_set1_pd(beta);
let alpha = _mm256_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][0], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][0], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][1], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][1], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][2], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][2], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm256_storeu_pd(dst, _mm256_fmadd_pd(beta, acc[0][3], _mm256_mul_pd(_mm256_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm256_maskstore_pd(dst, last_mask, _mm256_fmadd_pd(beta, acc[1][3], _mm256_mul_pd(_mm256_maskload_pd(dst, last_mask), alpha)));
}}}
pub static MICROKERNELS: [[[nano_gemm_core::MicroKernel<f64>; 4]; 2]; 17] = [
[
[
matmul_1_1_1,matmul_1_2_1,matmul_1_3_1,matmul_1_4_1,],
[
matmul_2_1_1,matmul_2_2_1,matmul_2_3_1,matmul_2_4_1,],
],
[
[
matmul_1_1_2,matmul_1_2_2,matmul_1_3_2,matmul_1_4_2,],
[
matmul_2_1_2,matmul_2_2_2,matmul_2_3_2,matmul_2_4_2,],
],
[
[
matmul_1_1_3,matmul_1_2_3,matmul_1_3_3,matmul_1_4_3,],
[
matmul_2_1_3,matmul_2_2_3,matmul_2_3_3,matmul_2_4_3,],
],
[
[
matmul_1_1_4,matmul_1_2_4,matmul_1_3_4,matmul_1_4_4,],
[
matmul_2_1_4,matmul_2_2_4,matmul_2_3_4,matmul_2_4_4,],
],
[
[
matmul_1_1_5,matmul_1_2_5,matmul_1_3_5,matmul_1_4_5,],
[
matmul_2_1_5,matmul_2_2_5,matmul_2_3_5,matmul_2_4_5,],
],
[
[
matmul_1_1_6,matmul_1_2_6,matmul_1_3_6,matmul_1_4_6,],
[
matmul_2_1_6,matmul_2_2_6,matmul_2_3_6,matmul_2_4_6,],
],
[
[
matmul_1_1_7,matmul_1_2_7,matmul_1_3_7,matmul_1_4_7,],
[
matmul_2_1_7,matmul_2_2_7,matmul_2_3_7,matmul_2_4_7,],
],
[
[
matmul_1_1_8,matmul_1_2_8,matmul_1_3_8,matmul_1_4_8,],
[
matmul_2_1_8,matmul_2_2_8,matmul_2_3_8,matmul_2_4_8,],
],
[
[
matmul_1_1_9,matmul_1_2_9,matmul_1_3_9,matmul_1_4_9,],
[
matmul_2_1_9,matmul_2_2_9,matmul_2_3_9,matmul_2_4_9,],
],
[
[
matmul_1_1_10,matmul_1_2_10,matmul_1_3_10,matmul_1_4_10,],
[
matmul_2_1_10,matmul_2_2_10,matmul_2_3_10,matmul_2_4_10,],
],
[
[
matmul_1_1_11,matmul_1_2_11,matmul_1_3_11,matmul_1_4_11,],
[
matmul_2_1_11,matmul_2_2_11,matmul_2_3_11,matmul_2_4_11,],
],
[
[
matmul_1_1_12,matmul_1_2_12,matmul_1_3_12,matmul_1_4_12,],
[
matmul_2_1_12,matmul_2_2_12,matmul_2_3_12,matmul_2_4_12,],
],
[
[
matmul_1_1_13,matmul_1_2_13,matmul_1_3_13,matmul_1_4_13,],
[
matmul_2_1_13,matmul_2_2_13,matmul_2_3_13,matmul_2_4_13,],
],
[
[
matmul_1_1_14,matmul_1_2_14,matmul_1_3_14,matmul_1_4_14,],
[
matmul_2_1_14,matmul_2_2_14,matmul_2_3_14,matmul_2_4_14,],
],
[
[
matmul_1_1_15,matmul_1_2_15,matmul_1_3_15,matmul_1_4_15,],
[
matmul_2_1_15,matmul_2_2_15,matmul_2_3_15,matmul_2_4_15,],
],
[
[
matmul_1_1_16,matmul_1_2_16,matmul_1_3_16,matmul_1_4_16,],
[
matmul_2_1_16,matmul_2_2_16,matmul_2_3_16,matmul_2_4_16,],
],
[
[
matmul_1_1_dyn,matmul_1_2_dyn,matmul_1_3_dyn,matmul_1_4_dyn,],
[
matmul_2_1_dyn,matmul_2_2_dyn,matmul_2_3_dyn,matmul_2_4_dyn,],
],
];

            pub static MASKS: [crate::x86::__m256i; 4] = unsafe { core::mem::transmute([
                [u64::MAX, u64::MAX, u64::MAX, u64::MAX],

                [u64::MAX, 0, 0, 0],
                [u64::MAX, u64::MAX, 0, 0],
                [u64::MAX, u64::MAX, u64::MAX, 0],
            ]) };
        }

        #[cfg(feature = "nightly")]
        pub mod avx512 {
pub const MR_DIV_N: usize = 2; pub const NR: usize = 4; pub const N: usize = 8;
            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let depth = 15;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let depth = 15;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let depth = 15;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 2;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 3;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 4;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 5;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 6;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 7;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 8;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 9;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 10;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 11;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 12;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 13;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 14;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
let depth = 15;
tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_1_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 1] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 1] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 0 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[0][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let depth = 15;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 1]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let depth = 15;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 2]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let depth = 15;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 3]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
let depth = 0;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][0] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][1] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][2] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_mul_pd(tmp_lhs[0], tmp_rhs);
acc[1][3] = _mm512_mul_pd(tmp_lhs[1], tmp_rhs);
let depth = 1;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 2;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 3;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 4;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 5;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 6;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 7;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 8;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 9;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 10;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 11;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 12;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 13;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 14;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
let depth = 15;
tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}

            #[target_feature(enable = "avx512f")]
pub unsafe fn matmul_2_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, last_mask, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {

                #[cfg(target_arch = "x86_64")]
                use core::arch::x86_64::*;
                #[cfg(target_arch = "x86")]
                use core::arch::x86::*;
            _ = k;
type Reg = __m512d;
const N: isize = 8;
let mut acc: [[Reg; 4]; 2] = core::mem::zeroed();
let mut tmp_lhs: [Reg; 2] = core::mem::zeroed();
let last_mask = *(last_mask as *const u8);
for depth in 0..k as isize {tmp_lhs[0] = _mm512_loadu_pd(lhs.offset(depth * lhs_cs + 0 * N));
tmp_lhs[1] = _mm512_maskz_loadu_pd(last_mask, lhs.offset(depth * lhs_cs + 1 * N));
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc[0][0] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][0]);
acc[1][0] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][0]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc[0][1] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][1]);
acc[1][1] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][1]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc[0][2] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][2]);
acc[1][2] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][2]);
let tmp_rhs = _mm512_set1_pd(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc[0][3] = _mm512_fmadd_pd(tmp_lhs[0], tmp_rhs, acc[0][3]);
acc[1][3] = _mm512_fmadd_pd(tmp_lhs[1], tmp_rhs, acc[1][3]);
}if alpha == 1.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_maskz_loadu_pd(last_mask, dst)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_loadu_pd(dst)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_maskz_loadu_pd(last_mask, dst)));
}}else if alpha == 0.0 {let beta = _mm512_set1_pd(beta);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][0]));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][0]));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][1]));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][1]));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][2]));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][2]));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_mul_pd(beta, acc[0][3]));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_mul_pd(beta, acc[1][3]));
}}else {let beta = _mm512_set1_pd(beta);
let alpha = _mm512_set1_pd(alpha);
{let dst = dst.offset(0 * N + 0 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][0], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 0 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][0], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 1 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][1], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 1 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][1], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 2 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][2], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 2 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][2], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}{let dst = dst.offset(0 * N + 3 * dst_cs);_mm512_storeu_pd(dst, _mm512_fmadd_pd(beta, acc[0][3], _mm512_mul_pd(_mm512_loadu_pd(dst), alpha)));
}{let dst = dst.offset(1 * N + 3 * dst_cs);_mm512_mask_storeu_pd(dst, last_mask, _mm512_fmadd_pd(beta, acc[1][3], _mm512_mul_pd(_mm512_maskz_loadu_pd(last_mask, dst), alpha)));
}}}
pub static MICROKERNELS: [[[nano_gemm_core::MicroKernel<f64>; 4]; 2]; 17] = [
[
[
matmul_1_1_1,matmul_1_2_1,matmul_1_3_1,matmul_1_4_1,],
[
matmul_2_1_1,matmul_2_2_1,matmul_2_3_1,matmul_2_4_1,],
],
[
[
matmul_1_1_2,matmul_1_2_2,matmul_1_3_2,matmul_1_4_2,],
[
matmul_2_1_2,matmul_2_2_2,matmul_2_3_2,matmul_2_4_2,],
],
[
[
matmul_1_1_3,matmul_1_2_3,matmul_1_3_3,matmul_1_4_3,],
[
matmul_2_1_3,matmul_2_2_3,matmul_2_3_3,matmul_2_4_3,],
],
[
[
matmul_1_1_4,matmul_1_2_4,matmul_1_3_4,matmul_1_4_4,],
[
matmul_2_1_4,matmul_2_2_4,matmul_2_3_4,matmul_2_4_4,],
],
[
[
matmul_1_1_5,matmul_1_2_5,matmul_1_3_5,matmul_1_4_5,],
[
matmul_2_1_5,matmul_2_2_5,matmul_2_3_5,matmul_2_4_5,],
],
[
[
matmul_1_1_6,matmul_1_2_6,matmul_1_3_6,matmul_1_4_6,],
[
matmul_2_1_6,matmul_2_2_6,matmul_2_3_6,matmul_2_4_6,],
],
[
[
matmul_1_1_7,matmul_1_2_7,matmul_1_3_7,matmul_1_4_7,],
[
matmul_2_1_7,matmul_2_2_7,matmul_2_3_7,matmul_2_4_7,],
],
[
[
matmul_1_1_8,matmul_1_2_8,matmul_1_3_8,matmul_1_4_8,],
[
matmul_2_1_8,matmul_2_2_8,matmul_2_3_8,matmul_2_4_8,],
],
[
[
matmul_1_1_9,matmul_1_2_9,matmul_1_3_9,matmul_1_4_9,],
[
matmul_2_1_9,matmul_2_2_9,matmul_2_3_9,matmul_2_4_9,],
],
[
[
matmul_1_1_10,matmul_1_2_10,matmul_1_3_10,matmul_1_4_10,],
[
matmul_2_1_10,matmul_2_2_10,matmul_2_3_10,matmul_2_4_10,],
],
[
[
matmul_1_1_11,matmul_1_2_11,matmul_1_3_11,matmul_1_4_11,],
[
matmul_2_1_11,matmul_2_2_11,matmul_2_3_11,matmul_2_4_11,],
],
[
[
matmul_1_1_12,matmul_1_2_12,matmul_1_3_12,matmul_1_4_12,],
[
matmul_2_1_12,matmul_2_2_12,matmul_2_3_12,matmul_2_4_12,],
],
[
[
matmul_1_1_13,matmul_1_2_13,matmul_1_3_13,matmul_1_4_13,],
[
matmul_2_1_13,matmul_2_2_13,matmul_2_3_13,matmul_2_4_13,],
],
[
[
matmul_1_1_14,matmul_1_2_14,matmul_1_3_14,matmul_1_4_14,],
[
matmul_2_1_14,matmul_2_2_14,matmul_2_3_14,matmul_2_4_14,],
],
[
[
matmul_1_1_15,matmul_1_2_15,matmul_1_3_15,matmul_1_4_15,],
[
matmul_2_1_15,matmul_2_2_15,matmul_2_3_15,matmul_2_4_15,],
],
[
[
matmul_1_1_16,matmul_1_2_16,matmul_1_3_16,matmul_1_4_16,],
[
matmul_2_1_16,matmul_2_2_16,matmul_2_3_16,matmul_2_4_16,],
],
[
[
matmul_1_1_dyn,matmul_1_2_dyn,matmul_1_3_dyn,matmul_1_4_dyn,],
[
matmul_2_1_dyn,matmul_2_2_dyn,matmul_2_3_dyn,matmul_2_4_dyn,],
],
];

            pub static MASKS: [u8; 8] = [
                0b1111_1111,
                0b0000_0001,
                0b0000_0011,
                0b0000_0111,
                0b0000_1111,
                0b0001_1111,
                0b0011_1111,
                0b0111_1111,
            ];
        }
}
}
        #[cfg(target_arch = "aarch64")]
        pub mod aarch64 {
    pub mod f64 {
pub mod neon {

            use core::arch::aarch64::*;
            use core::mem::transmute;
            use core::mem::transmute_copy;

            #[inline(always)]
            unsafe fn set1(v: f64) -> float64x2_t {
                transmute([v; 2])
            }
            #[inline(always)]
            unsafe fn mul_add(a: float64x2_t, b: float64x2_t, c: float64x2_t) -> float64x2_t {
                vmlaq_f64(c, a, b)
            }
            #[inline(always)]
            unsafe fn load_1(ptr: *const f64) -> float64x2_t {
                transmute([*ptr; 2])
            }
            #[inline(always)]
            unsafe fn load_2(ptr: *const f64) -> float64x2_t {
                transmute(*(ptr as *const [f64; 2]))
            }

            #[inline(always)]
            unsafe fn store_1(ptr: *mut f64, v: float64x2_t) {
                *(ptr as *mut [f64; 1]) = transmute_copy(&v);
            }
            #[inline(always)]
            unsafe fn store_2(ptr: *mut f64, v: float64x2_t) {
                *(ptr as *mut [f64; 2]) = transmute_copy(&v);
            }
            #[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 15;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 15;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 15;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 13;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 14;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 15;
let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_1_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_1(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_2_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_3_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_1(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, load_1(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, load_1(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, load_1(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, load_1(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_1(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_1(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_1(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_1(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_1(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_1_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_2_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_3_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_1(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_2(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_3(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_4(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_5(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_6(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_7(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_8(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_9(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_10(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_11(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_12(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_13(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_14(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_15(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_16(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
let depth = 0;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 1;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 2;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 3;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 4;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 5;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 6;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 7;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 8;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 9;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 10;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 11;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 12;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 13;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 14;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
let depth = 15;
let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}#[target_feature(enable = "neon")]
pub unsafe fn matmul_4_4_dyn(
                &nano_gemm_core::MicroKernelData { alpha, beta, k, dst_cs, lhs_cs, rhs_rs, rhs_cs, .. }: &nano_gemm_core::MicroKernelData< f64 >,
                dst: *mut f64,
                lhs: *const f64,
                rhs: *const f64,
            ) {
_ = k;
let mut acc_0_0: float64x2_t = core::mem::zeroed();
let mut acc_0_1: float64x2_t = core::mem::zeroed();
let mut acc_0_2: float64x2_t = core::mem::zeroed();
let mut acc_0_3: float64x2_t = core::mem::zeroed();
let mut acc_2_0: float64x2_t = core::mem::zeroed();
let mut acc_2_1: float64x2_t = core::mem::zeroed();
let mut acc_2_2: float64x2_t = core::mem::zeroed();
let mut acc_2_3: float64x2_t = core::mem::zeroed();
for depth in 0..k as isize {let tmp_lhs_0 = load_2(lhs.offset(depth * lhs_cs + 0));let tmp_lhs_2 = load_2(lhs.offset(depth * lhs_cs + 2));let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 0 * rhs_cs));
acc_0_0 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_0);
acc_2_0 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_0);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 1 * rhs_cs));
acc_0_1 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_1);
acc_2_1 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_1);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 2 * rhs_cs));
acc_0_2 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_2);
acc_2_2 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_2);
let tmp_rhs = set1(*rhs.offset(depth * rhs_rs + 3 * rhs_cs));
acc_0_3 = mul_add(tmp_lhs_0, tmp_rhs, acc_0_3);
acc_2_3 = mul_add(tmp_lhs_2, tmp_rhs, acc_2_3);
}if alpha == 1.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, load_2(dst)));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, load_2(dst)));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, load_2(dst)));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, load_2(dst)));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, load_2(dst)));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, load_2(dst)));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, load_2(dst)));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, load_2(dst)));
}}else if alpha == 0.0 {let beta = set1(beta);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, core::mem::zeroed()));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, core::mem::zeroed()));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, core::mem::zeroed()));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, core::mem::zeroed()));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, core::mem::zeroed()));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, core::mem::zeroed()));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, core::mem::zeroed()));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, core::mem::zeroed()));
}}else {let beta = set1(beta);
let alpha = set1(alpha);
{let dst = dst.offset(0 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_0_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 0 * dst_cs);store_2(dst, mul_add(beta, acc_2_0, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_0_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 1 * dst_cs);store_2(dst, mul_add(beta, acc_2_1, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_0_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 2 * dst_cs);store_2(dst, mul_add(beta, acc_2_2, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(0 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_0_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}{let dst = dst.offset(2 + 3 * dst_cs);store_2(dst, mul_add(beta, acc_2_3, mul_add(alpha, load_2(dst), core::mem::zeroed())));
}}}pub static MICROKERNELS: [[[nano_gemm_core::MicroKernel<f64>; 4]; 4]; 17] = [
[
[
matmul_1_1_1,matmul_1_2_1,matmul_1_3_1,matmul_1_4_1,],
[
matmul_2_1_1,matmul_2_2_1,matmul_2_3_1,matmul_2_4_1,],
[
matmul_3_1_1,matmul_3_2_1,matmul_3_3_1,matmul_3_4_1,],
[
matmul_4_1_1,matmul_4_2_1,matmul_4_3_1,matmul_4_4_1,],
],
[
[
matmul_1_1_2,matmul_1_2_2,matmul_1_3_2,matmul_1_4_2,],
[
matmul_2_1_2,matmul_2_2_2,matmul_2_3_2,matmul_2_4_2,],
[
matmul_3_1_2,matmul_3_2_2,matmul_3_3_2,matmul_3_4_2,],
[
matmul_4_1_2,matmul_4_2_2,matmul_4_3_2,matmul_4_4_2,],
],
[
[
matmul_1_1_3,matmul_1_2_3,matmul_1_3_3,matmul_1_4_3,],
[
matmul_2_1_3,matmul_2_2_3,matmul_2_3_3,matmul_2_4_3,],
[
matmul_3_1_3,matmul_3_2_3,matmul_3_3_3,matmul_3_4_3,],
[
matmul_4_1_3,matmul_4_2_3,matmul_4_3_3,matmul_4_4_3,],
],
[
[
matmul_1_1_4,matmul_1_2_4,matmul_1_3_4,matmul_1_4_4,],
[
matmul_2_1_4,matmul_2_2_4,matmul_2_3_4,matmul_2_4_4,],
[
matmul_3_1_4,matmul_3_2_4,matmul_3_3_4,matmul_3_4_4,],
[
matmul_4_1_4,matmul_4_2_4,matmul_4_3_4,matmul_4_4_4,],
],
[
[
matmul_1_1_5,matmul_1_2_5,matmul_1_3_5,matmul_1_4_5,],
[
matmul_2_1_5,matmul_2_2_5,matmul_2_3_5,matmul_2_4_5,],
[
matmul_3_1_5,matmul_3_2_5,matmul_3_3_5,matmul_3_4_5,],
[
matmul_4_1_5,matmul_4_2_5,matmul_4_3_5,matmul_4_4_5,],
],
[
[
matmul_1_1_6,matmul_1_2_6,matmul_1_3_6,matmul_1_4_6,],
[
matmul_2_1_6,matmul_2_2_6,matmul_2_3_6,matmul_2_4_6,],
[
matmul_3_1_6,matmul_3_2_6,matmul_3_3_6,matmul_3_4_6,],
[
matmul_4_1_6,matmul_4_2_6,matmul_4_3_6,matmul_4_4_6,],
],
[
[
matmul_1_1_7,matmul_1_2_7,matmul_1_3_7,matmul_1_4_7,],
[
matmul_2_1_7,matmul_2_2_7,matmul_2_3_7,matmul_2_4_7,],
[
matmul_3_1_7,matmul_3_2_7,matmul_3_3_7,matmul_3_4_7,],
[
matmul_4_1_7,matmul_4_2_7,matmul_4_3_7,matmul_4_4_7,],
],
[
[
matmul_1_1_8,matmul_1_2_8,matmul_1_3_8,matmul_1_4_8,],
[
matmul_2_1_8,matmul_2_2_8,matmul_2_3_8,matmul_2_4_8,],
[
matmul_3_1_8,matmul_3_2_8,matmul_3_3_8,matmul_3_4_8,],
[
matmul_4_1_8,matmul_4_2_8,matmul_4_3_8,matmul_4_4_8,],
],
[
[
matmul_1_1_9,matmul_1_2_9,matmul_1_3_9,matmul_1_4_9,],
[
matmul_2_1_9,matmul_2_2_9,matmul_2_3_9,matmul_2_4_9,],
[
matmul_3_1_9,matmul_3_2_9,matmul_3_3_9,matmul_3_4_9,],
[
matmul_4_1_9,matmul_4_2_9,matmul_4_3_9,matmul_4_4_9,],
],
[
[
matmul_1_1_10,matmul_1_2_10,matmul_1_3_10,matmul_1_4_10,],
[
matmul_2_1_10,matmul_2_2_10,matmul_2_3_10,matmul_2_4_10,],
[
matmul_3_1_10,matmul_3_2_10,matmul_3_3_10,matmul_3_4_10,],
[
matmul_4_1_10,matmul_4_2_10,matmul_4_3_10,matmul_4_4_10,],
],
[
[
matmul_1_1_11,matmul_1_2_11,matmul_1_3_11,matmul_1_4_11,],
[
matmul_2_1_11,matmul_2_2_11,matmul_2_3_11,matmul_2_4_11,],
[
matmul_3_1_11,matmul_3_2_11,matmul_3_3_11,matmul_3_4_11,],
[
matmul_4_1_11,matmul_4_2_11,matmul_4_3_11,matmul_4_4_11,],
],
[
[
matmul_1_1_12,matmul_1_2_12,matmul_1_3_12,matmul_1_4_12,],
[
matmul_2_1_12,matmul_2_2_12,matmul_2_3_12,matmul_2_4_12,],
[
matmul_3_1_12,matmul_3_2_12,matmul_3_3_12,matmul_3_4_12,],
[
matmul_4_1_12,matmul_4_2_12,matmul_4_3_12,matmul_4_4_12,],
],
[
[
matmul_1_1_13,matmul_1_2_13,matmul_1_3_13,matmul_1_4_13,],
[
matmul_2_1_13,matmul_2_2_13,matmul_2_3_13,matmul_2_4_13,],
[
matmul_3_1_13,matmul_3_2_13,matmul_3_3_13,matmul_3_4_13,],
[
matmul_4_1_13,matmul_4_2_13,matmul_4_3_13,matmul_4_4_13,],
],
[
[
matmul_1_1_14,matmul_1_2_14,matmul_1_3_14,matmul_1_4_14,],
[
matmul_2_1_14,matmul_2_2_14,matmul_2_3_14,matmul_2_4_14,],
[
matmul_3_1_14,matmul_3_2_14,matmul_3_3_14,matmul_3_4_14,],
[
matmul_4_1_14,matmul_4_2_14,matmul_4_3_14,matmul_4_4_14,],
],
[
[
matmul_1_1_15,matmul_1_2_15,matmul_1_3_15,matmul_1_4_15,],
[
matmul_2_1_15,matmul_2_2_15,matmul_2_3_15,matmul_2_4_15,],
[
matmul_3_1_15,matmul_3_2_15,matmul_3_3_15,matmul_3_4_15,],
[
matmul_4_1_15,matmul_4_2_15,matmul_4_3_15,matmul_4_4_15,],
],
[
[
matmul_1_1_16,matmul_1_2_16,matmul_1_3_16,matmul_1_4_16,],
[
matmul_2_1_16,matmul_2_2_16,matmul_2_3_16,matmul_2_4_16,],
[
matmul_3_1_16,matmul_3_2_16,matmul_3_3_16,matmul_3_4_16,],
[
matmul_4_1_16,matmul_4_2_16,matmul_4_3_16,matmul_4_4_16,],
],
[
[
matmul_1_1_dyn,matmul_1_2_dyn,matmul_1_3_dyn,matmul_1_4_dyn,],
[
matmul_2_1_dyn,matmul_2_2_dyn,matmul_2_3_dyn,matmul_2_4_dyn,],
[
matmul_3_1_dyn,matmul_3_2_dyn,matmul_3_3_dyn,matmul_3_4_dyn,],
[
matmul_4_1_dyn,matmul_4_2_dyn,matmul_4_3_dyn,matmul_4_4_dyn,],
],
];
}}}